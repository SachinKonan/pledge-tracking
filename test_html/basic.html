<!DOCTYPE html>
<html>
<head>
    <title>PoseNet - Camera Feed Demo</title>
    <!-- Load TensorFlow.js -->
    <script src="https://unpkg.com/@tensorflow/tfjs"></script>
    <!-- Load Posenet -->
    <script src="https://unpkg.com/@tensorflow-models/posenet">
    </script>
    <style>
        .footer {
            position: fixed;
            left: 0;
            bottom: 0;
            width: 100%;
            color: black;
        }

        .footer-text {
            max-width: 600px;
            text-align: center;
            margin: auto;
        }
    </style>
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
    <div id="info" style='display:none'>
    </div>
    <div id='main' class="'footer-text">
        <video id="video" autoplay playsinline style='display:none'>
        </video>
        <canvas id="output" />
    </div>
    <div class="footer">
        <div class="footer-text">
            <p>
                PoseNet runs with either a <strong>single-pose</strong> or <strong>multi-pose</strong> detection
                algorithm. The single person pose detector is faster and more accurate but requires only one subject
                present in the image.
                <br>
                <br> The <strong>output stride</strong> and <strong>input resolution</strong> have the largest effects
                on accuracy/speed. A <i>higher</i> output stride results in lower accuracy but higher speed. A
                <i>higher</i> image scale factor results in higher accuracy but lower speed. </p>
        </div>
    </div>
    <script src="draw.js"></script>
    <script src="utilities.js"></script>

</body>
</html>